#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç…§æ˜ãƒ¢ãƒ¼ãƒ‰æ¤œå‡ºãƒ‡ãƒ¢ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³
ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§ã®ç…§æ˜ãƒ¢ãƒ¼ãƒ‰è¡¨ç¤ºã¨çµ±è¨ˆæƒ…å ±
"""

import os
import sys
# UTF-8ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°å¼·åˆ¶è¨­å®š
if sys.stdout.encoding != 'UTF-8':
    os.environ['PYTHONIOENCODING'] = 'utf-8'
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

import cv2
import numpy as np
import time
from datetime import datetime
import argparse
from PIL import Image, ImageDraw, ImageFont

# å¿…è¦ãªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from phase3_hamster_tracking.utils.lighting_detector import LightingModeDetector, SimpleLightingDetector
from rtsp_stream import RTSPStream
from utils.camera_config import get_camera_config

def put_japanese_text(image, text, position, font_size=20, color=(255, 255, 255)):
    """
    OpenCVç”»åƒã«æ—¥æœ¬èªãƒ†ã‚­ã‚¹ãƒˆã‚’æç”»
    
    Args:
        image: OpenCVç”»åƒ (BGR)
        text: æç”»ã™ã‚‹æ—¥æœ¬èªãƒ†ã‚­ã‚¹ãƒˆ
        position: æç”»ä½ç½® (x, y)
        font_size: ãƒ•ã‚©ãƒ³ãƒˆã‚µã‚¤ã‚º
        color: æ–‡å­—è‰² (B, G, R)
    
    Returns:
        æç”»å¾Œã®ç”»åƒ
    """
    try:
        # OpenCV BGR -> PIL RGB
        pil_image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
        draw = ImageDraw.Draw(pil_image)
        
        # æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆä½¿ç”¨
        try:
            font = ImageFont.truetype("/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc", font_size)
        except:
            try:
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯1: åˆ¥ã®CJKãƒ•ã‚©ãƒ³ãƒˆ
                font = ImageFont.truetype("/usr/share/fonts/opentype/noto/NotoSansCJK-Bold.ttc", font_size)
            except:
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯2: ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
                font = ImageFont.load_default()
        
        # PILè‰²å½¢å¼ã«å¤‰æ› (RGB)
        pil_color = (color[2], color[1], color[0])
        
        # ãƒ†ã‚­ã‚¹ãƒˆæç”»
        draw.text(position, text, font=font, fill=pil_color)
        
        # PIL RGB -> OpenCV BGR
        return cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2BGR)
    
    except Exception as e:
        # ã‚¨ãƒ©ãƒ¼æ™‚ã¯è‹±èªã§ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        fallback_text = text.encode('ascii', 'replace').decode('ascii')
        cv2.putText(image, fallback_text, position, cv2.FONT_HERSHEY_SIMPLEX, 
                   font_size/30, color, 1)
        return image

class LightingDetectionDemo:
    """ç…§æ˜æ¤œå‡ºãƒ‡ãƒ¢ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, use_simple: bool = False, stream_type: str = "sub"):
        """
        åˆæœŸåŒ–
        
        Args:
            use_simple: è»½é‡ç‰ˆæ¤œå‡ºå™¨ä½¿ç”¨ãƒ•ãƒ©ã‚°
            stream_type: RTSPã‚¹ãƒˆãƒªãƒ¼ãƒ ç¨®åˆ¥ ("main" or "sub")
        """
        # æ¤œå‡ºå™¨åˆæœŸåŒ–
        if use_simple:
            self.detector = SimpleLightingDetector()
            self.detector_name = "SimpleLightingDetector"
        else:
            self.detector = LightingModeDetector()
            self.detector_name = "LightingModeDetector"
        
        # RTSPè¨­å®š
        self.stream_type = stream_type
        self.config = get_camera_config()
        self.config.set_password("894890abc")
        
        # çµ±è¨ˆæƒ…å ±
        self.stats = {
            'total_frames': 0,
            'ir_frames': 0,
            'color_frames': 0,
            'unknown_frames': 0,
            'avg_confidence': 0.0,
            'avg_processing_time': 0.0,
            'start_time': time.time()
        }
        
        # è¡¨ç¤ºè¨­å®š
        self.font = cv2.FONT_HERSHEY_SIMPLEX
        self.font_scale = 0.7
        self.thickness = 2
        
        # è‰²è¨­å®š
        self.colors = {
            'ir': (0, 100, 255),      # ã‚ªãƒ¬ãƒ³ã‚¸ï¼ˆIRï¼‰
            'color': (0, 255, 0),     # ç·‘ï¼ˆã‚«ãƒ©ãƒ¼ï¼‰
            'unknown': (128, 128, 128), # ã‚°ãƒ¬ãƒ¼ï¼ˆä¸æ˜ï¼‰
            'text': (255, 255, 255),   # ç™½ï¼ˆãƒ†ã‚­ã‚¹ãƒˆï¼‰
            'background': (0, 0, 0)    # é»’ï¼ˆèƒŒæ™¯ï¼‰
        }
        
        print(f"ğŸ¯ ç…§æ˜æ¤œå‡ºãƒ‡ãƒ¢åˆæœŸåŒ–å®Œäº†")
        print(f"   æ¤œå‡ºå™¨: {self.detector_name}")
        print(f"   ã‚¹ãƒˆãƒªãƒ¼ãƒ : {stream_type}")
    
    def run_demo(self, duration: int = 300):
        """
        ãƒ‡ãƒ¢å®Ÿè¡Œ
        
        Args:
            duration: å®Ÿè¡Œæ™‚é–“ï¼ˆç§’ï¼‰ã€0ã§ç„¡åˆ¶é™
        """
        print(f"=== ç…§æ˜æ¤œå‡ºãƒ‡ãƒ¢é–‹å§‹ ({duration}ç§’é–“) ===")
        print("æ“ä½œæ–¹æ³•:")
        print("  'q' / ESC: çµ‚äº†")
        print("  's': çµ±è¨ˆãƒªã‚»ãƒƒãƒˆ")
        print("  'i': æƒ…å ±è¡¨ç¤ºåˆ‡ã‚Šæ›¿ãˆ")
        print("  'h': ãƒ˜ãƒ«ãƒ—è¡¨ç¤º")
        
        try:
            with RTSPStream(self.stream_type, buffer_size=1) as stream:
                if not stream.start_stream():
                    print("âŒ RTSPã‚¹ãƒˆãƒªãƒ¼ãƒ é–‹å§‹å¤±æ•—")
                    return False
                
                print("âœ… RTSPã‚¹ãƒˆãƒªãƒ¼ãƒ é–‹å§‹æˆåŠŸ")
                
                # OpenCVã‚¦ã‚£ãƒ³ãƒ‰ã‚¦è¨­å®š
                window_name = "ç…§æ˜ãƒ¢ãƒ¼ãƒ‰æ¤œå‡ºãƒ‡ãƒ¢"
                cv2.namedWindow(window_name, cv2.WINDOW_AUTOSIZE)
                
                start_time = time.time()
                show_info = True
                
                while True:
                    # æ™‚é–“åˆ¶é™ãƒã‚§ãƒƒã‚¯
                    if duration > 0 and (time.time() - start_time) > duration:
                        print(f"â° æ™‚é–“åˆ¶é™ ({duration}ç§’) ã«åˆ°é”")
                        break
                    
                    # ãƒ•ãƒ¬ãƒ¼ãƒ å–å¾—
                    result = stream.get_frame(timeout=1.0)
                    if not result or not result[0]:
                        continue
                    
                    success, frame = result
                    self.stats['total_frames'] += 1
                    
                    # ç…§æ˜ãƒ¢ãƒ¼ãƒ‰æ¤œå‡º
                    detection_start = time.time()
                    if isinstance(self.detector, LightingModeDetector):
                        mode, confidence, details = self.detector.detect_mode(frame)
                        processing_time = details['processing_time_ms']
                    else:
                        mode, confidence = self.detector.detect_mode(frame)
                        processing_time = (time.time() - detection_start) * 1000
                        details = {}
                    
                    # çµ±è¨ˆæ›´æ–°
                    self._update_stats(mode, confidence, processing_time)
                    
                    # ãƒ•ãƒ¬ãƒ¼ãƒ ã«æƒ…å ±æç”»
                    display_frame = self._draw_info_on_frame(
                        frame, mode, confidence, details, show_info
                    )
                    
                    # ãƒ•ãƒ¬ãƒ¼ãƒ è¡¨ç¤º
                    cv2.imshow(window_name, display_frame)
                    
                    # ã‚­ãƒ¼å…¥åŠ›å‡¦ç†
                    key = cv2.waitKey(1) & 0xFF
                    if key == ord('q') or key == 27:  # 'q' or ESC
                        print("ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ˆã‚‹çµ‚äº†")
                        break
                    elif key == ord('s'):
                        self._reset_stats()
                        print("ğŸ“Š çµ±è¨ˆæƒ…å ±ã‚’ãƒªã‚»ãƒƒãƒˆã—ã¾ã—ãŸ")
                    elif key == ord('i'):
                        show_info = not show_info
                        print(f"â„¹ï¸ æƒ…å ±è¡¨ç¤º: {'ON' if show_info else 'OFF'}")
                    elif key == ord('h'):
                        self._show_help()
                
                cv2.destroyAllWindows()
                
                # æœ€çµ‚çµ±è¨ˆè¡¨ç¤º
                self._show_final_stats()
                
                return True
                
        except Exception as e:
            print(f"âŒ ãƒ‡ãƒ¢å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def _draw_info_on_frame(self, frame: np.ndarray, mode: str, confidence: float,
                           details: dict, show_info: bool = True) -> np.ndarray:
        """
        ãƒ•ãƒ¬ãƒ¼ãƒ ã«æƒ…å ±ã‚’æç”»
        
        Args:
            frame: å…ƒãƒ•ãƒ¬ãƒ¼ãƒ 
            mode: æ¤œå‡ºãƒ¢ãƒ¼ãƒ‰
            confidence: ä¿¡é ¼åº¦
            details: è©³ç´°æƒ…å ±
            show_info: è©³ç´°æƒ…å ±è¡¨ç¤ºãƒ•ãƒ©ã‚°
            
        Returns:
            æç”»æ¸ˆã¿ãƒ•ãƒ¬ãƒ¼ãƒ 
        """
        display_frame = frame.copy()
        h, w = frame.shape[:2]
        
        # ãƒ¢ãƒ¼ãƒ‰è¡¨ç¤ºï¼ˆå¤§ããä¸­å¤®ä¸Šéƒ¨ï¼‰
        mode_text = f"ãƒ¢ãƒ¼ãƒ‰: {mode.upper()}"
        mode_color = self.colors.get(mode, self.colors['unknown'])
        
        # ãƒ†ã‚­ã‚¹ãƒˆã‚µã‚¤ã‚ºè¨ˆç®—
        (text_w, text_h), baseline = cv2.getTextSize(
            mode_text, self.font, self.font_scale * 1.5, self.thickness
        )
        
        # èƒŒæ™¯çŸ©å½¢
        cv2.rectangle(display_frame, 
                     (w//2 - text_w//2 - 10, 10),
                     (w//2 + text_w//2 + 10, 10 + text_h + baseline + 20),
                     self.colors['background'], -1)
        
        # ãƒ¢ãƒ¼ãƒ‰ãƒ†ã‚­ã‚¹ãƒˆï¼ˆæ—¥æœ¬èªå¯¾å¿œï¼‰
        display_frame = put_japanese_text(display_frame, mode_text,
                                        (w//2 - text_w//2, 10 + text_h + 10),
                                        font_size=int(self.font_scale * 30), color=mode_color)
        
        # ä¿¡é ¼åº¦ãƒãƒ¼
        bar_width = 200
        bar_height = 20
        bar_x = w//2 - bar_width//2
        bar_y = 60
        
        # ãƒãƒ¼èƒŒæ™¯
        cv2.rectangle(display_frame,
                     (bar_x, bar_y),
                     (bar_x + bar_width, bar_y + bar_height),
                     (50, 50, 50), -1)
        
        # ä¿¡é ¼åº¦ãƒãƒ¼
        filled_width = int(bar_width * confidence)
        cv2.rectangle(display_frame,
                     (bar_x, bar_y),
                     (bar_x + filled_width, bar_y + bar_height),
                     mode_color, -1)
        
        # ä¿¡é ¼åº¦ãƒ†ã‚­ã‚¹ãƒˆï¼ˆæ—¥æœ¬èªå¯¾å¿œï¼‰
        conf_text = f"ä¿¡é ¼åº¦: {confidence:.3f}"
        display_frame = put_japanese_text(display_frame, conf_text,
                                        (bar_x, bar_y + bar_height + 20),
                                        font_size=int(self.font_scale * 20), color=self.colors['text'])
        
        if show_info and details:
            self._draw_detailed_info(display_frame, details)
        
        # çµ±è¨ˆæƒ…å ±ï¼ˆå³ä¸‹ï¼‰
        self._draw_stats_info(display_frame)
        
        # ç¾åœ¨æ™‚åˆ»ï¼ˆå·¦ä¸Šï¼‰
        current_time = datetime.now().strftime("%H:%M:%S")
        cv2.putText(display_frame, current_time,
                   (10, 30), self.font, self.font_scale, 
                   self.colors['text'], 1)
        
        # æ“ä½œãƒ˜ãƒ«ãƒ—ï¼ˆå·¦ä¸‹ï¼‰
        help_text = "q:çµ‚äº† s:çµ±è¨ˆãƒªã‚»ãƒƒãƒˆ i:æƒ…å ±åˆ‡æ›¿ h:ãƒ˜ãƒ«ãƒ—"
        cv2.putText(display_frame, help_text,
                   (10, h - 10), self.font, 0.5, 
                   self.colors['text'], 1)
        
        return display_frame
    
    def _draw_detailed_info(self, frame: np.ndarray, details: dict):
        """è©³ç´°æƒ…å ±æç”»"""
        h, w = frame.shape[:2]
        info_x = 10
        info_y = 80
        line_height = 25
        
        # è©³ç´°æƒ…å ±ãƒªã‚¹ãƒˆ
        info_lines = [
            f"RGBç›¸é–¢: {details.get('rgb_correlation', 0):.3f}",
            f"æ™‚åˆ»æ¨å®š: {details.get('time_estimation', 0):.3f}",
            f"è‰²ç›¸å¤šæ§˜æ€§: {details.get('hue_diversity', 0):.3f}",
            f"ã‚¨ãƒƒã‚¸å¯†åº¦: {details.get('edge_density', 0):.3f}",
            f"å“è³ªã‚¹ã‚³ã‚¢: {details.get('frame_quality', 0):.3f}",
            f"å‡¦ç†æ™‚é–“: {details.get('processing_time_ms', 0):.1f}ms",
            f"å±¥æ­´ã‚µã‚¤ã‚º: {details.get('history_size', 0)}"
        ]
        
        # èƒŒæ™¯çŸ©å½¢
        max_width = max([cv2.getTextSize(line, self.font, 0.5, 1)[0][0] for line in info_lines])
        cv2.rectangle(frame,
                     (info_x - 5, info_y - 5),
                     (info_x + max_width + 10, info_y + len(info_lines) * line_height + 5),
                     (0, 0, 0, 128), -1)
        
        # è©³ç´°æƒ…å ±æç”»
        for i, line in enumerate(info_lines):
            cv2.putText(frame, line,
                       (info_x, info_y + i * line_height),
                       self.font, 0.5, self.colors['text'], 1)
    
    def _draw_stats_info(self, frame: np.ndarray):
        """çµ±è¨ˆæƒ…å ±æç”»"""
        h, w = frame.shape[:2]
        stats_x = w - 200
        stats_y = h - 150
        line_height = 20
        
        elapsed_time = time.time() - self.stats['start_time']
        fps = self.stats['total_frames'] / max(elapsed_time, 1)
        
        # çµ±è¨ˆæƒ…å ±
        stats_lines = [
            f"ç·ãƒ•ãƒ¬ãƒ¼ãƒ : {self.stats['total_frames']}",
            f"FPS: {fps:.1f}",
            f"IR: {self.stats['ir_frames']}",
            f"ã‚«ãƒ©ãƒ¼: {self.stats['color_frames']}",
            f"å¹³å‡ä¿¡é ¼åº¦: {self.stats['avg_confidence']:.3f}",
            f"å¹³å‡å‡¦ç†æ™‚é–“: {self.stats['avg_processing_time']:.1f}ms"
        ]
        
        # èƒŒæ™¯çŸ©å½¢
        cv2.rectangle(frame,
                     (stats_x - 5, stats_y - 5),
                     (w - 5, stats_y + len(stats_lines) * line_height + 5),
                     (0, 0, 0, 128), -1)
        
        # çµ±è¨ˆæƒ…å ±æç”»
        for i, line in enumerate(stats_lines):
            cv2.putText(frame, line,
                       (stats_x, stats_y + i * line_height),
                       self.font, 0.5, self.colors['text'], 1)
    
    def _update_stats(self, mode: str, confidence: float, processing_time: float):
        """çµ±è¨ˆæƒ…å ±æ›´æ–°"""
        if mode == 'ir':
            self.stats['ir_frames'] += 1
        elif mode == 'color':
            self.stats['color_frames'] += 1
        else:
            self.stats['unknown_frames'] += 1
        
        # ç§»å‹•å¹³å‡æ›´æ–°
        alpha = 0.1
        self.stats['avg_confidence'] = (
            alpha * confidence + (1 - alpha) * self.stats['avg_confidence']
        )
        self.stats['avg_processing_time'] = (
            alpha * processing_time + (1 - alpha) * self.stats['avg_processing_time']
        )
    
    def _reset_stats(self):
        """çµ±è¨ˆæƒ…å ±ãƒªã‚»ãƒƒãƒˆ"""
        self.stats = {
            'total_frames': 0,
            'ir_frames': 0,
            'color_frames': 0,
            'unknown_frames': 0,
            'avg_confidence': 0.0,
            'avg_processing_time': 0.0,
            'start_time': time.time()
        }
        
        if hasattr(self.detector, 'reset_stats'):
            self.detector.reset_stats()
    
    def _show_help(self):
        """ãƒ˜ãƒ«ãƒ—è¡¨ç¤º"""
        print("\n=== æ“ä½œãƒ˜ãƒ«ãƒ— ===")
        print("  'q' ã¾ãŸã¯ ESC: ãƒ‡ãƒ¢çµ‚äº†")
        print("  's': çµ±è¨ˆæƒ…å ±ãƒªã‚»ãƒƒãƒˆ")
        print("  'i': è©³ç´°æƒ…å ±è¡¨ç¤ºåˆ‡ã‚Šæ›¿ãˆ")
        print("  'h': ã“ã®ãƒ˜ãƒ«ãƒ—è¡¨ç¤º")
        print("")
    
    def _show_final_stats(self):
        """æœ€çµ‚çµ±è¨ˆè¡¨ç¤º"""
        print("\n=== æœ€çµ‚çµ±è¨ˆæƒ…å ± ===")
        
        total = self.stats['total_frames']
        if total == 0:
            print("å‡¦ç†ãƒ•ãƒ¬ãƒ¼ãƒ ãªã—")
            return
        
        elapsed = time.time() - self.stats['start_time']
        
        print(f"å®Ÿè¡Œæ™‚é–“: {elapsed:.1f}ç§’")
        print(f"ç·ãƒ•ãƒ¬ãƒ¼ãƒ : {total}")
        print(f"å¹³å‡FPS: {total/elapsed:.1f}")
        print(f"")
        print(f"æ¤œå‡ºçµæœ:")
        print(f"  IRåˆ¤å®š: {self.stats['ir_frames']} ({self.stats['ir_frames']/total:.1%})")
        print(f"  ã‚«ãƒ©ãƒ¼åˆ¤å®š: {self.stats['color_frames']} ({self.stats['color_frames']/total:.1%})")
        print(f"  ä¸æ˜åˆ¤å®š: {self.stats['unknown_frames']} ({self.stats['unknown_frames']/total:.1%})")
        print(f"")
        print(f"æ€§èƒ½æŒ‡æ¨™:")
        print(f"  å¹³å‡ä¿¡é ¼åº¦: {self.stats['avg_confidence']:.3f}")
        print(f"  å¹³å‡å‡¦ç†æ™‚é–“: {self.stats['avg_processing_time']:.1f}ms")
        
        # æ¤œå‡ºå™¨ã®çµ±è¨ˆãŒã‚ã‚Œã°è¡¨ç¤º
        if hasattr(self.detector, 'get_detection_stats'):
            detector_stats = self.detector.get_detection_stats()
            print(f"\næ¤œå‡ºå™¨çµ±è¨ˆ:")
            for key, value in detector_stats.items():
                if isinstance(value, float):
                    print(f"  {key}: {value:.3f}")
                else:
                    print(f"  {key}: {value}")

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    parser = argparse.ArgumentParser(description='ç…§æ˜ãƒ¢ãƒ¼ãƒ‰æ¤œå‡ºãƒ‡ãƒ¢')
    parser.add_argument('--simple', action='store_true', 
                       help='è»½é‡ç‰ˆæ¤œå‡ºå™¨ã‚’ä½¿ç”¨')
    parser.add_argument('--stream', choices=['main', 'sub'], default='sub',
                       help='RTSPã‚¹ãƒˆãƒªãƒ¼ãƒ ç¨®åˆ¥')
    parser.add_argument('--duration', type=int, default=0,
                       help='å®Ÿè¡Œæ™‚é–“ï¼ˆç§’ï¼‰ã€0ã§ç„¡åˆ¶é™')
    
    args = parser.parse_args()
    
    # ãƒ‡ãƒ¢å®Ÿè¡Œ
    demo = LightingDetectionDemo(
        use_simple=args.simple,
        stream_type=args.stream
    )
    
    success = demo.run_demo(duration=args.duration)
    
    if success:
        print("\nğŸ‰ ãƒ‡ãƒ¢å®Œäº†")
    else:
        print("\nâŒ ãƒ‡ãƒ¢å¤±æ•—")

if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nãƒ‡ãƒ¢ä¸­æ–­")
    except Exception as e:
        print(f"\nãƒ‡ãƒ¢ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()